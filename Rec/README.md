# 推荐中常用的特征处理方法

- People generally consider DNNs as universal function approximators, that could potentially learn all kinds of feature interactions. However, recent studies found that DNNs are inefficient to even approximately model 2nd or 3rd-order feature crosses. -《DCN》作者

- 前记
    - 模型可以在一定程度上学习到特征的一些变换和组合，例如PNN、DCN、DeepFM、xDeepFM、AutoInt等模型可以建模特征的交叉组合，但是模型仍然很难学习到基于列的特征变换，这是因为模型一次只能接受一个批量大小的数据，无法建模全局的统计聚合信息，而这些信息往往是特别重要的
    - AutoFE自动特征组合主要依赖于特征变换、生成、搜索与评估，其无法自动识别场景的特殊性，难以评估特征子集的有效性
    - 好的特征应该具有的性质（区分性、特征之间相互独立、简单易于理解、伸缩性、高效性、灵活性、自适应）

- 用户侧
    - 用户粒度，也即从单个用户或者某一类用户出发，基于类别的统计对于缓解冷启动来说有重大意义
    - 时间粒度，从过去的几个小时，过去几周、过去几个月至今，这里在统计太长的时间粒度（例如首次使用至今）的时候需要考虑时间衰减，对于用户长期历史的统计（可以通过hadhoop/spark完成），对于用户短期历史的统计（可以直接访问线上redis缓存）
    - 物料粒度，可以是物品id，或者物品的属性，级别、标签等
    - 行为特征，包括正向（点击、有效观看时长、点赞、转发、收藏、评论等），负向（忽略、短播、踩、拉黑、不感兴趣等）
    - 统计对象包括次数、时长、金额等
    - 统计方法包括收集保存格式，计算XTR、计算占比等

- 物品侧
    - 对于item侧，最重要的应该是item的后验统计数据，主要有来自时间粒度和统计对象（CTR、平均播放进度、平均消费时长）的数据，这些统计数据是有偏的，也即有的商品推荐对了但是其不一定适合所有人，利用后验统计数据做特征会在一定程度上加剧马太效应，前期后验数据好的item可能会排得更加靠前，这样不利于新item的冷启动，这里可以另外建立一个模型根据现有的信息来预测后验数据

- 交叉特征
    - 直接对两两特征做特征交叉会导致特征数量暴涨，耗费大量的资源，另外其扩展性也特别差
    - 尝试的解决思路[《Explicit Semantic Cross Feature Learning via Pre-trained Graph Neural Networks for CTR Prediction》SIGIR2021](https://arxiv.org/pdf/2105.07752.pdf),该论文指出通过链接预估训练一个GNN模型，然后将用户侧与物品侧特征输入GNN，用输出的xtr作为特征，该方法节省了存储和计算开销，其基于embedding的，因此扩展性也比较好，借鉴上述思想可以将GNN换成FM模型来学习xtr，针对每一对特征点积之后再经过sigmoid函数，得到的xtr用于训练或者预测
- 特征收缩
    - 在计算梯度的时候数量级比较大的值对梯度的支配会比较重要，因此对具有不同的数量级的特征进行特征缩放处理是一个必要的操作，不做特征缩放，取值范围比较大的特征维度会支配距离函数的计算，使得其他特征失去原本应该有的作用，常用的特征缩放技术如下
    $$x_{norm}=\frac{x-\min(x)}{\max{x}-\min{x}} \in [0,1], Min-Max$$
    $$x_{norm}=\frac{x-mean(x)}{\max{x}-\min{x}} \in [0,1], Scale$$
    $$x_{norm}=\frac{x-mean(x)}{std(x)} \tilde N(0,1), Z-score$$
    $$x_{\log}=\log(1+x), x_{\log-norm}=\frac{x_{\log}-mean(x_{\log})}{std(x_{\log})}, log-based$$
    $$x_{norm}=\frac{x}{||x||_{2}}, L2 normalization$$
    $$Gauss Rank-Rank()-Scale()-erfinv-output$$


- 技巧
    - 可以利用用户给物品反向打标签来缓解冷启动问题，例如top10好看的电影，这些都是用户消费反向给物品打上的极其重要的标签


- 思考题
    - 如何量化视频的流行度？（播放次数）
    参考答案：短视频的播放次数在整个样本空间上遵循幂律分布，少量热门的视频播放次数会很高，大量长尾的视频播放次数都较少。这个时候比较好的做法是先做log based的变换，也就是先对播放次数取log，再对log变换之后的值做z-score标准化变换。如果不先做log变换，就直接做z-score或者min-max变换，会导致特征值被压缩到一个非常狭窄的区域

    - 如何量化商品对于用户的接受程度？（贵或者便宜）
    参考答案：商品的价格本身无法衡量商品“贵”或“便宜”的程度，因为不同品类的商品价格区间本来就可能差异很大，同样的价格买不同类型的产品给顾客的感受也是不一样的，比如，1000块钱买到一部手机，顾客感觉很便宜；但同样1000块钱买一只鼠标，顾客就会觉得这个商品的定价很贵。因此，量化商品“贵”或者“便宜”的程度时就必须要考虑商品的品类，这里推荐的做法是做z-score标准化变化，但需要注意的是商品价格的均值和标准差的计算都需要限制在同品类的商品集合内。    

    - 如何量化用户对某一题材的偏好度？
    参考答案：为了简化，假设我们就用用户一段时间内对某类新闻的阅读数量表示用户对该类新闻题材的偏好度。因为不同用户的活跃度是不同的，有些高活跃度用户可能会对多个不同题材的新闻阅读量都很大，而另一些低活跃度的用户可能只对有限的几种类型的新闻有中等的阅读量，我们不能因为高活跃度的用户对某题材的阅读量大于低活跃度用户对相同题材的的阅读量，就得出高活跃度用户对这种类型的偏好度大于低活跃度用户对同类型题材的偏好度，这是因为低活跃度用户的虽然阅读量较少，但却几乎把有限精力全部贡献给了该类型的题材，高活跃度的用户虽然阅读量较大，但却对多种题材“雨露均沾”。建议做min-max归一化，但需要注意的是计算最小值和最大值时都限制在当前用户的数据上，也就是按照用户分组，组内再做min-max归一化。

    - 如何对存在异常值的特征进行缩放？
    参考答案：当存在异常值时，除了第6种gauss rank特征变换方法外，其他的特征缩放方法都可能把转换后的特征值压缩到一个非常狭窄的区间内，从而使得这些特征失去区分度，如下图。这里介绍一种新的称之为Robust scaling的特征变换方法。
    $$x_{scale}=\frac{x-median(x)}{IQR}$$
    IQR为四分位距，用于确定第三四分位数和第一四分位数的差值。


    - 为什么要进行特征分箱？
        （1）引入非线性变换，可以增强模型的性能；
        （2）增强特征可解释性；
        （3）对异常值不敏感、防止过拟合；
        （4）分箱之后可以对不同的桶做进一步的统计和组合（与其他特征的交叉）；
    - 常见的分箱方法
        （1）无监督分箱：固定宽度分箱（时间、阈值等）、分位数分箱、对数转换并取整；
        （2）有监督分箱：卡方分箱、决策树分箱

    - 如何度量用户的购买力？如何给用户的购买力划分档位？
    参考答案：第一步是给商品划分价格档位。根据商品的类目分组，组类按照商品价格排序，并按照等频或者等宽的分箱方式，得到价格档位。第二步是聚合用户的购买力档位。根据用户的历史消费行为，把购买商品的价格档位聚合到用户身上。

    - 地理位置（经纬度）如何做分箱？
    参考答案：一个物理量如何有多个维度才能表示，那么在做分箱时不能拆分成独立的多个变量来单独做分箱，而要这些变量当成一个整体来考虑。经纬度的分箱有一个成熟的算法叫做GeoHash。


- 参考资料
    - [推荐系统|特征工程中的技巧](https://mp.weixin.qq.com/s/SBeN0KKVJEroyzIsto04ig)
    - [搜广推特征处理](https://mp.weixin.qq.com/s/Qml2OwR-Pu9yqiKxGp1T5Q)

